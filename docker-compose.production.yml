version: '3.8'

# WP-02: Production Docker Compose - Non-Root Hardened Services
# All services use the hardened base image with non-root user 'ai'

networks:
  ai_system_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16

volumes:
  redis_data:
    driver: local
  postgres_data:
    driver: local
  logs_data:
    driver: local
  models_data:
    driver: local
  data_storage:
    driver: local

services:
  # ===================================
  # SHARED INFRASTRUCTURE
  # ===================================
  
  redis:
    image: redis:7-alpine
    container_name: ai-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - ai_system_network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ===================================
  # CORE SERVICES
  # ===================================

  service-registry:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-service-registry
    restart: unless-stopped
    user: "1000:1000"  # ai user
    command: ["python", "-m", "main_pc_code.agents.service_registry_agent"]
    ports:
      - "7200:7200"
      - "8200:8200"
    environment:
      - SERVICE_REGISTRY_PORT=7200
      - SERVICE_REGISTRY_HEALTH_PORT=8200
      - SERVICE_REGISTRY_BIND_ADDRESS=0.0.0.0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - logs_data:/app/logs
      - data_storage:/app/data
    networks:
      - ai_system_network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import zmq; ctx=zmq.Context(); sock=ctx.socket(zmq.REQ); sock.connect('tcp://${LOCALHOST:-localhost}:7200'); sock.send_string('ping'); resp=sock.recv_string(zmq.NOBLOCK if True else 0); print(resp)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  system-digital-twin:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-system-digital-twin
    restart: unless-stopped
    user: "1000:1000"  # ai user
    command: ["python", "-m", "main_pc_code.agents.system_digital_twin"]
    ports:
      - "7220:7220"
      - "8220:8220"
    environment:
      - SYSTEM_DIGITAL_TWIN_PORT=7220
      - SYSTEM_DIGITAL_TWIN_HEALTH_PORT=8220
      - SERVICE_REGISTRY_HOST=service-registry
      - SERVICE_REGISTRY_PORT=7200
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - UNIFIED_MEMORY_DB_PATH=/app/data/unified_memory.db
      - BIND_ADDRESS=0.0.0.0
    volumes:
      - logs_data:/app/logs
      - data_storage:/app/data
    networks:
      - ai_system_network
    depends_on:
      service-registry:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://${LOCALHOST:-localhost}:8220/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s

  request-coordinator:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-request-coordinator
    restart: unless-stopped
    user: "1000:1000"  # ai user
    command: ["python", "-m", "main_pc_code.agents.request_coordinator"]
    ports:
      - "26002:26002"
      - "27002:27002"
    environment:
      - REQUEST_COORDINATOR_PORT=26002
      - REQUEST_COORDINATOR_HEALTH_PORT=27002
      - SYSTEM_DIGITAL_TWIN_HOST=system-digital-twin
      - SYSTEM_DIGITAL_TWIN_PORT=7220
      - BIND_ADDRESS=0.0.0.0
    volumes:
      - logs_data:/app/logs
      - data_storage:/app/data
    networks:
      - ai_system_network
    depends_on:
      system-digital-twin:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import zmq; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ===================================
  # MODEL MANAGEMENT
  # ===================================

  model-manager-suite:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-model-manager-suite
    restart: unless-stopped
    user: "1000:1000"  # ai user
    command: ["python", "-m", "main_pc_code.11"]
    ports:
      - "7211:7211"
      - "8211:8211"
    environment:
      - MODEL_MANAGER_SUITE_PORT=7211
      - MODEL_MANAGER_SUITE_HEALTH_PORT=8211
      - REQUEST_COORDINATOR_HOST=request-coordinator
      - REQUEST_COORDINATOR_PORT=26002
      - SYSTEM_DIGITAL_TWIN_HOST=system-digital-twin
      - VRAM_LIMIT_GB=24
      - MAX_CONCURRENT_MODELS=3
      - BIND_ADDRESS=0.0.0.0
    volumes:
      - logs_data:/app/logs
      - models_data:/app/models
      - data_storage:/app/data
    networks:
      - ai_system_network
    depends_on:
      request-coordinator:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; print('GPU:', torch.cuda.is_available())"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s

  # ===================================
  # STREAMING SERVICES
  # ===================================

  streaming-interrupt-handler:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-streaming-interrupt-handler
    restart: unless-stopped
    user: "1000:1000"  # ai user
    command: ["python", "-m", "main_pc_code.agents.streaming_interrupt_handler"]
    ports:
      - "5576:5576"
      - "6576:6576"
    environment:
      - STREAMING_INTERRUPT_PORT=5576
      - STREAMING_INTERRUPT_HEALTH_PORT=6576
      - STREAMING_STT_HOST=streaming-stt
      - STREAMING_TTS_HOST=streaming-tts
      - SYSTEM_DIGITAL_TWIN_HOST=system-digital-twin
      - BIND_ADDRESS=0.0.0.0
    volumes:
      - logs_data:/app/logs
    networks:
      - ai_system_network
    depends_on:
      system-digital-twin:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "print('Streaming service OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ===================================
  # OBSERVABILITY & MONITORING
  # ===================================

  observability-hub:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-observability-hub
    restart: unless-stopped
    user: "1000:1000"  # ai user
    command: ["python", "-m", "phase0_implementation.group_01_core_observability.observability_hub.observability_hub"]
    ports:
      - "9000:9000"
      - "9100:9100"
    environment:
      - OBSERVABILITY_HUB_PORT=9000
      - OBSERVABILITY_HUB_HEALTH_PORT=9100
      - PROMETHEUS_HOST=prometheus
      - PROMETHEUS_PORT=9090
      - SYSTEM_DIGITAL_TWIN_HOST=system-digital-twin
      - BIND_ADDRESS=0.0.0.0
      - ENABLE_METRICS=true
      - ENABLE_TRACING=true
    volumes:
      - logs_data:/app/logs
      - data_storage:/app/data
    networks:
      - ai_system_network
    depends_on:
      system-digital-twin:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://${LOCALHOST:-localhost}:9100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ===================================
  # DEVELOPMENT & DEBUGGING
  # ===================================

  ai-shell:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: ai-debug-shell
    restart: "no"
    user: "1000:1000"  # ai user
    command: ["sleep", "infinity"]
    environment:
      - BIND_ADDRESS=0.0.0.0
      - LOG_LEVEL=DEBUG
    volumes:
      - logs_data:/app/logs
      - models_data:/app/models
      - data_storage:/app/data
      - .:/app/source:ro  # Read-only source mount for debugging
    networks:
      - ai_system_network
    depends_on:
      - redis
    profiles:
      - debug  # Only start with: docker-compose --profile debug up

# ===================================
# CONFIGURATION EXTENSIONS
# ===================================

# Override file for local development
# Use: docker-compose -f docker-compose.production.yml -f docker-compose.override.yml up
# Create docker-compose.override.yml with local customizations 