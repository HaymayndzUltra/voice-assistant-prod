[
  {
    "id": "memory_fusion_hub_implementation",
    "description": "A comprehensive, multi-phase action plan to implement the Memory Fusion Hub (MFH) based on the provided architectural blueprint.",
    "todos": [
      {
        "text": "PHASE 0: SETUP & PROTOCOL (READ FIRST)\n\n**Explanations:**\nThis initial step contains the user manual for this task plan. It outlines the commands to interact with the plan and the critical safety workflow that must be followed for all subsequent phases.\n\n**Technical Artifacts:**\n**I. CORE BEHAVIORAL MANDATES (FOR THE EXECUTING AI - READ FIRST)**\n1.  **Validate Assumptions:** Before starting, validate your assumptions about the task using the provided details.\n2.  **Clarify Ambiguity:** If information is ambiguous or missing, seek clarification before proceeding.\n3.  **Highlight Conflicts:** If you detect errors or conflicts in the data, highlight them immediately and suggest alternatives.\n4.  **Explain Rationale:** During execution, explain the rationale for each step taken.\n5.  **Review Before Submission:** Before submitting the final output, review the entire process to correct any errors or flawed assumptions.\n6.  **STOP ON ERROR (CRUCIAL):** If any command or step results in an error, **STOP IMMEDIATELY**. Do not proceed to the next step. Analyze the error, apply a fix, and re-run the failed step until it succeeds before continuing.\n\n**II. HOW TO USE THIS TASK PLAN (COMMANDS & PROTOCOL)**\n\n1.  **COMMANDS:**\n    *   **TO VIEW DETAILS:** `python3 todo_manager.py show memory_fusion_hub_implementation`\n    *   **TO MARK AS DONE:** `python3 todo_manager.py done memory_fusion_hub_implementation <step_number>`\n\n2.  **WORKFLOW & SAFETY PROTOCOL (CRUCIAL):**\n    *   **FOCUS ON CURRENT STEP:** In each Phase, always read and understand the `IMPORTANT NOTE` first.\n    *   **REVIEW-CONFIRM-PROCEED LOOP:** After completing a Phase, review your work and the next Phase. If your confidence score is below 90%, REPEAT the review.\n\n──────────────────────────────────\nIMPORTANT NOTE: This phase contains the operating manual for the entire plan. Understanding these protocols is mandatory before proceeding to Phase 1. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 1: Scaffolding & Initial Setup\n\n**Explanations:**\nThis phase involves creating the complete directory structure for the `memory_fusion_hub` service and copying in canonical utility files as a starting point for the resiliency components.\n\n**Technical Artifacts / Tasks:**\n**1. Create Directory Structure:**\n```bash\nmkdir -p memory_fusion_hub/config\nmkdir -p memory_fusion_hub/adapters\nmkdir -p memory_fusion_hub/core\nmkdir -p memory_fusion_hub/transport\nmkdir -p memory_fusion_hub/resiliency\ntouch memory_fusion_hub/__init__.py\ntouch memory_fusion_hub/app.py\ntouch memory_fusion_hub/README.md\n```\n\n**2. Copy Canonical Utilities:**\n```bash\ncp common/resiliency/bulkhead.py memory_fusion_hub/resiliency/\ncp main_pc_code/agents/memory_client.py memory_fusion_hub/resiliency/circuit_breaker.py\n# Note: The blueprint specifies to keep only the class definition and tests from the copied files.\n```\n\n──────────────────────────────────\nIMPORTANT NOTE: A correct directory structure is fundamental. Verify all folders and copied files are in the correct locations before proceeding to the next phase. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 2: Dependency & Configuration Setup\n\n**Explanations:**\nThis phase defines the project's dependencies and establishes the default configuration schema that will govern the behavior of the Memory Fusion Hub.\n\n**Technical Artifacts / Tasks:**\n**1. Create `requirements.txt`:**\n```bash\ncat > memory_fusion_hub/requirements.txt <<'REQ'\npydantic==1.10.13\npyzmq==26.0.3\ngrpcio==1.63.0\ngrpcio-tools==1.63.0\nredis==5.0.1\nsqlalchemy==2.0.30\naiosqlite==0.19.0\nprometheus-client==0.20.0\ntenacity==8.2.3\nREQ\n```\n\n**2. Create Default Configuration (`config/default.yaml`):**\n```yaml\ntitle: MemoryFusionHubConfig\nversion: 1.0\n\nserver:\n  zmq_port: 5713\n  grpc_port: 5714\n  max_workers: 8\n\nstorage:\n  write_strategy: \"event_sourcing\"   # options: direct, event_sourcing\n  sqlite_path: \"${MFH_SQLITE:/workspace/memory.db}\"\n  postgres_url: \"${POSTGRES_URL:}\"\n  redis_url: \"${REDIS_URL:redis://localhost:6379/0}\"\n  cache_ttl_seconds: 900\n\nreplication:\n  enabled: true\n  event_topic: \"memory_events\"\n  nats_url: \"${NATS_URL:nats://localhost:4222}\"\n\nresilience:\n  circuit_breaker:\n    failure_threshold: 5\n    reset_timeout: 30\n  bulkhead:\n    max_concurrent: 32\n    max_queue_size: 128\n```\n\n**3. Install Dependencies:**\n```bash\npip install -r memory_fusion_hub/requirements.txt\n```\n\n──────────────────────────────────\nIMPORTANT NOTE: The configuration file defines critical parameters like ports and storage paths. Ensure it is created correctly. The `pip install` command must complete successfully. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 3: Core Logic & Data Modeling Implementation\n\n**Explanations:**\nThis phase focuses on building the foundational components of the service: data models, storage abstractions (repositories), and cache adapters.\n\n**Technical Artifacts / Tasks:**\n*   **`core/models.py`:** Implement Pydantic objects: `MemoryItem`, `SessionData`, `KnowledgeRecord`, `MemoryEvent`. Include JSON-schema generation.\n*   **`core/repository.py`:** Define the `AbstractRepository` interface and create concrete implementations (`SQLiteRepository`, `PostgresRepository`).\n    ```python\n    class AbstractRepository(ABC):\n        @abstractmethod\n        async def get(self, key: str) -> Optional[BaseModel]: ...\n        @abstractmethod\n        async def put(self, key: str, value: BaseModel) -> None: ...\n        @abstractmethod\n        async def delete(self, key: str) -> None: ...\n    ```\n*   **`adapters/sqlite_adapter.py` & `adapters/postgres_adapter.py`:** Implement the logic for the concrete repositories defined in `core/repository.py`.\n*   **`adapters/redis_cache.py`:** Implement the TTL-aware cache logic.\n\n──────────────────────────────────\nIMPORTANT NOTE: The data models and repository pattern are the architectural backbone. Ensure the Pydantic models are correct and the repository interface is strictly followed by the concrete implementations. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 4: Service & Event Sourcing Implementation\n\n**Explanations:**\nThis phase implements the main business logic (`FusionService`), the event sourcing mechanism, and integrates the resiliency patterns.\n\n**Technical Artifacts / Tasks:**\n*   **`core/event_log.py`:** Implement the append-only log writer using Redis Streams or NATS JetStream. It should publish `MemoryEvent` objects.\n*   **`core/telemetry.py`:** Implement Prometheus counters and histograms for monitoring.\n*   **`core/fusion_service.py`:** Implement the `FusionService` class, which is the heart of the MFH.\n    ```python\n    class FusionService:\n        def __init__(self, cfg: FusionConfig):\n            self.cache = RedisCache(cfg.storage.redis_url, cfg.storage.cache_ttl_seconds)\n            self.repo = build_repo(cfg.storage)\n            self.event_log = EventLog(cfg.replication)\n            self.metrics = Telemetry()\n            self.lock = asyncio.Lock()\n\n        @retry_with_backoff(...)\n        async def get(self, key: str) -> MemoryItem: ...\n\n        @bulkhead_guard\n        async def put(self, key: str, item: MemoryItem): ...\n\n        async def delete(self, key: str): ...\n    ```\n\n──────────────────────────────────\nIMPORTANT NOTE: The `FusionService` orchestrates all core components. Pay close attention to the use of locks for write operations and the correct application of the `@bulkhead_guard` and `@retry_with_backoff` decorators. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 5: Transport Layer Implementation\n\n**Explanations:**\nThis phase builds the external-facing APIs (ZMQ and gRPC) that will expose the `FusionService` logic to other agents.\n\n**Technical Artifacts / Tasks:**\n*   **`transport/zmq_server.py`:** Implement the ZMQ REQ/REP server. It should receive requests, call the appropriate `FusionService` method, and return the result.\n*   **Create `memory_fusion.proto`:** Define the gRPC service and messages.\n    ```proto\n    service MemoryFusionService {\n      rpc Get(GetRequest) returns (GetResponse);\n      rpc Put(PutRequest) returns (PutResponse);\n      rpc Delete(DeleteRequest) returns (DeleteResponse);\n      rpc BatchGet(BatchGetRequest) returns (BatchGetResponse);\n    }\n    ```\n*   **Compile gRPC Stubs:**\n    ```bash\n    python -m grpc_tools.protoc -I. --python_out=memory_fusion_hub/ --grpc_python_out=memory_fusion_hub/ memory_fusion.proto\n    ```\n*   **`transport/grpc_server.py`:** Implement the gRPC server using the compiled stubs. It should call the same shared `FusionService` instance.\n\n──────────────────────────────────\nIMPORTANT NOTE: The transport layer is the entry point for all clients. Ensure that request/response data is correctly serialized and deserialized using Pydantic models (for ZMQ) and Protobuf messages (for gRPC). **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 6: Application Bootstrap & Entry-Point\n\n**Explanations:**\nThis phase creates the main application entry point (`app.py`), which is responsible for loading configuration, initializing all services, and handling graceful shutdowns.\n\n**Technical Artifacts / Tasks:**\n*   **`app.py` Implementation:**\n    1.  Load configuration using `UnifiedConfigLoader` (loading `default.yaml`, host-specific overrides, and environment variables).\n    2.  Initialize a single instance of `FusionService`.\n    3.  Start the Prometheus HTTP endpoint.\n    4.  Launch the ZMQ and gRPC servers asynchronously (e.g., using `asyncio.gather`).\n    5.  Implement signal handlers for `SIGTERM` and `SIGINT` to ensure graceful shutdown (flushing event logs, closing DB connections).\n\n──────────────────────────────────\nIMPORTANT NOTE: The bootstrap script ties everything together. Proper configuration loading and graceful shutdown logic are critical for a production-ready service. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 7: Testing & Verification\n\n**Explanations:**\nThis is the final quality gate. This phase involves comprehensive testing to ensure the service is robust, performant, and correct according to the design.\n\n**Technical Artifacts / Tasks:**\n*   **Unit Tests:** Write and run `pytest` tests for the repository, cache, and `FusionService` logic.\n*   **Static Analysis:** Run `mypy --strict` and `flake8` to ensure code quality and type safety.\n*   **Integration Tests:** Test the full request-response cycle through both ZMQ and gRPC endpoints. Verify that a write on one replica is visible on another within the expected time frame.\n*   **Load Test:** Use a tool like Locust to verify performance targets (e.g., ≤ 20 ms p95 latency at 1k rps).\n*   **Failover Drill:** Manually kill a primary MFH process and verify that a replica can continue serving requests without data loss.\n*   **Audit Test:** Use the `event_log.replay()` function to rehydrate a database from the event log and verify its checksum matches the original.\n\n──────────────────────────────────\nIMPORTANT NOTE: This phase is critical for ensuring production readiness. Do not proceed to deployment until all tests pass and performance targets are met. The \"Risk Mitigation Checklist\" from the blueprint should guide the focus of these tests. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 8: Deployment, Migration & Documentation\n\n**Explanations:**\nThe final phase involves deploying the Memory Fusion Hub, migrating client traffic to it, decommissioning legacy systems, and creating comprehensive documentation.\n\n**Technical Artifacts / Tasks:**\n*   **Deployment:** Deploy two replicas of the MFH per host, ideally behind a load balancer like a `zmq.ROUTER` socket.\n*   **Traffic Migration:** Update existing agents (e.g., `LearningManager`) to point to the new MFH port (5713).\n*   **Decommission:** Once traffic is fully migrated and stable, archive the seven superseded legacy memory agents.\n*   **Final Documentation:**\n    *   Update the main project `README.md` with a detailed description of the Memory Fusion Hub, its architecture, and its configuration.\n    *   Create architecture diagrams showing the MFH, its components (Redis, DB), and its interaction with other agents.\n    *   Document the ZMQ and gRPC API schemas for client developers.\n    *   Collate all \"Known Issues\" and performance test results into the documentation.\n\n──────────────────────────────────\nIMPORTANT NOTE: The migration must be performed carefully to avoid service disruption. Monitor the system closely after switching traffic. Comprehensive documentation is essential for future maintenance and development. **If you encounter any errors, do not proceed. Fix the issue before moving to the next step.** Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      }
    ],
    "status": "in_progress",
    "created": "2024-05-24T12:40:00Z",
    "updated": "2024-05-24T12:40:00Z"
  }
]