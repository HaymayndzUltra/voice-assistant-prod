[
  {
    "id": "ai_execution_playbook",
    "description": "A multi-phase plan to build, push, pull, run, and validate a set of AI services across two machines (MainPC and PC2).",
    "todos": [
      {
        "text": "PHASE 0: SETUP & PROTOCOL (READ FIRST)\n\n**Explanations:**\nThis initial step contains the user manual for this task plan. It outlines the commands to interact with the plan and the critical safety workflow that must be followed for all subsequent phases.\n\n**Technical Artifacts:**\n**I. CORE BEHAVIORAL MANDATES (FOR THE EXECUTING AI - READ FIRST)**\n1.  **Validate Assumptions:** Before starting, validate your assumptions about the task using the provided details.\n2.  **Clarify Ambiguity:** If information is ambiguous or missing, seek clarification before proceeding.\n3.  **Highlight Conflicts:** If you detect errors or conflicts in the data, highlight them immediately and suggest alternatives.\n4.  **Explain Rationale:** During execution, explain the rationale for each step taken.\n5.  **Review Before Submission:** Before submitting the final output, review the entire process to correct any errors or flawed assumptions.\n\n**II. HOW TO USE THIS TASK PLAN (COMMANDS & PROTOCOL)**\n\n1.  **COMMANDS:**\n    *   **TO VIEW DETAILS:** `python3 todo_manager.py show ai_execution_playbook`\n    *   **TO MARK AS DONE:** `python3 todo_manager.py done ai_execution_playbook <step_number>`\n\n2.  **WORKFLOW & SAFETY PROTOCOL (CRUCIAL):**\n    *   **FOCUS ON CURRENT STEP:** In each Phase, always read and understand the `IMPORTANT NOTE` first.\n    *   **REVIEW-CONFIRM-PROCEED LOOP:** After completing a Phase, review your work and the next Phase. If your confidence score is below 90%, REPEAT the review.\n\n──────────────────────────────────\nIMPORTANT NOTE: This phase contains the operating manual for the entire plan. Understanding these protocols is mandatory before proceeding to Phase 1. Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": true
      },
      {
        "text": "PHASE 1: PREREQUISITES CHECK\n\n**Explanations:**\nVerify that the environment meets all necessary hardware, software, and repository requirements before starting the build process.\n\n**Technical Artifacts / Tasks:**\n*   MainPC host (RTX 4090 / Ryzen 9 7900) with Docker Engine ≥ 24 and Internet ↔ container-registry access.\n*   PC2 host (RTX 3060) with Docker Engine running and able to pull from the same registry.\n*   Both machines have a clone of the monorepo under the same absolute path, e.g. `/home/haymayndz/AI_System_Monorepo`.\n*   Registry variable: `REGISTRY=ghcr.io/<org>` (replace `<org>`).\n*   Git branch `main` up-to-date.\n\n──────────────────────────────────\nIMPORTANT NOTE: Ensure both machines are correctly configured and the repository is up-to-date. Failure to meet these prerequisites will cause subsequent phases to fail. Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": true
      },
      {
        "text": "PHASE 2: MainPC (build & push)\n\n**Explanations:**\nOn the MainPC, set environment variables, patch Dockerfiles, generate dependency locks, and then build and push the required Docker images to the specified registry.\n\n**Technical Artifacts / Tasks:**\n1.  **Set env vars once**\n    ```bash\n    export REGISTRY=ghcr.io/<org>\n    export TAG=pc2-latest\n    export DOCKER_BUILDKIT=1\n    cd /home/haymayndz/AI_System_Monorepo\n    ```\n2.  **Patch ALL Dockerfiles (idempotent)**\n    ```bash\n    python3 scripts/patch_dockerfiles.py --apply\n    ```\n3.  **Generate / refresh dependency lock**\n    ```bash\n    python3 -m pip install -q pip-tools\n    pip-compile requirements.common.txt --generate-hashes -q -o requirements.common.lock.txt\n    ```\n4.  **Build + push only PC2 images**\n    ```bash\n    for dir in docker/pc2_* ; do\n        name=$(basename \"$dir\")\n        image=\"$REGISTRY/$name:$TAG\"\n        docker build -t \"$image\" \"$dir\"\n        docker push \"$image\"\n    done\n    ```\n5.  **OPTIONAL: Build + push MainPC images (same loop but `docker/` paths without `pc2_` prefix).**\n\n──────────────────────────────────\nIMPORTANT NOTE: This phase performs the heavy build tasks on the MainPC. Ensure you have registry write access and that the `DOCKER_BUILDKIT=1` variable is set for efficient builds. Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 3: PC2 (pull & run)\n\n**Explanations:**\nOn PC2, set environment variables, pull the newly built images from the registry, create a Docker Compose file, and start the services.\n\n**Technical Artifacts / Tasks:**\n6.  **On PC2 host**\n    ```bash\n    export REGISTRY=ghcr.io/<org>\n    export TAG=pc2-latest\n    cd /home/haymayndz/AI_System_Monorepo\n    ```\n7.  **Pull all required images**\n    ```bash\n    for dir in docker/pc2_* ; do\n        name=$(basename \"$dir\")\n        docker pull \"$REGISTRY/$name:$TAG\"\n    done\n    ```\n8.  **Create compose file `compose/pc2.yml` (one-time) – example entry shown:**\n    ```yaml\n    version: \"3.9\"\n    services:\n      VisionProcessingAgent:\n        image: ghcr.io/<org>/pc2_vision_processing_agent:pc2-latest\n        deploy:\n          resources:\n            reservations:\n              devices:\n                - capabilities: [\"gpu\"]\n        environment:\n          TORCH_CUDA_ALLOC_CONF: max_split_size_mb:64\n          INT8_QUANT: \"1\"\n        ports: [\"7150:7150\"]\n\n    # repeat for each agent in startup_config.yaml (pc2_services list)\n    ```\n9.  **Bring stack up**\n    ```bash\n    docker compose -f compose/pc2.yml up -d\n    ```\n10. **Verify**\n    ```bash\n    docker compose -f compose/pc2.yml ps\n    curl http://localhost:8150/health   # VisionProcessingAgent\n    nvidia-smi -q -d MEMORY | grep Used\n    ```\n\n──────────────────────────────────\nIMPORTANT NOTE: This phase brings the services online on the second machine. Ensure Docker has access to the GPU and that the ports specified in the compose file are available. Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      },
      {
        "text": "PHASE 4: Validation (either Host)\n\n**Explanations:**\nPerform final validation by running unit tests and a final acceptance script. This phase also lists the key guarantees that should be met upon successful completion.\n\n**Technical Artifacts / Tasks:**\n11. **Run unit tests (will skip Docker-heavy tests unless daemon present):**\n    ```bash\n    python3 -m venv .venv && source .venv/bin/activate\n    pip install -q -r requirements.common.txt pyzmq redis pyyaml docker pytest\n    SKIP_DOCKER_TESTS=1 pytest -q\n    ```\n12. **Final acceptance gate**\n    ```bash\n    python scripts/final_validation.py\n    # prints ✅ Task plan satisfied • all validations passed\n    ```\n**Key Guarantees Achieved:**\n*   Shared `requirements.common.txt` layer → one cached wheel set for every image.\n*   All PC2 images built with identical core versions (locked file).\n*   Heavy build CPU/GPU work done on MainPC; PC2 only pulls layers.\n*   GPU memory on PC2 kept < 12 GB via INT8/hybrid flags.\n*   Tests succeed locally; full integration tests can run when Docker daemon available.\n\n──────────────────────────────────\nIMPORTANT NOTE: This is the final verification step. The `final_validation.py` script is the ultimate gate for success. Confirm that all key guarantees listed have been met. Do not proceed until the current step is complete. Before moving forward, review the completed step and the next one. Repeat the review if your confidence score is below 90%.",
        "done": false
      }
    ],
    "status": "in_progress",
    "created": "2024-05-24T12:00:00Z",
    "updated": "2025-08-06T18:49:50.272375+08:00"
  }
]