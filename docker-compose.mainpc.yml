version: "3.9"
name: mainpc_stack

services:
  # ============================================================================
  # INFRASTRUCTURE - Redis (Cross-machine access point)
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: mainpc-redis
    command: ["redis-server", "--appendonly", "yes"]
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    networks:
      - backplane
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================================
  # CONTAINER GROUP 1: CORE SERVICES (4 agents)
  # ServiceRegistry, SystemDigitalTwin, RequestCoordinator, ObservabilityHub
  # ============================================================================
  core_services:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/core_services:latest
    container_name: mainpc-core-services
    command: python -m main_pc_code.system_launcher_containerized --groups core_services
    environment:
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
      - PORT_OFFSET=0
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - backplane
    ports:
      - "7200:7200"   # ServiceRegistry
      - "7220:7220"   # SystemDigitalTwin
      - "26002:26002" # RequestCoordinator
      - "9000:9000"   # ObservabilityHub
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s

  # ============================================================================
  # CONTAINER GROUP 2: GPU INTENSIVE (4 agents)
  # ModelManagerSuite, ChainOfThoughtAgent, VRAMOptimizerAgent, ModelOrchestrator
  # ============================================================================
  gpu_intensive:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/gpu_suite:latest
    container_name: mainpc-gpu-intensive
    command: python -m main_pc_code.system_launcher_containerized --groups gpu_infrastructure,reasoning_services
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
    depends_on:
      - core_services
    networks:
      - backplane
    ports:
      - "7211:7211"   # ModelManagerSuite
      - "5612:5612"   # ChainOfThoughtAgent
      - "5572:5572"   # VRAMOptimizerAgent
      - "7213:7213"   # ModelOrchestrator
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: "8"
        reservations:
          devices:
            - capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:7211/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s

  # ============================================================================
  # CONTAINER GROUP 3: LANGUAGE PIPELINE (6 agents)
  # NLUAgent, AdvancedCommandHandler, TranslationService, ChitchatAgent, Responder, IntentionValidatorAgent
  # ============================================================================
  language_pipeline:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/language_pipeline:latest
    container_name: mainpc-language-pipeline
    command: python -m main_pc_code.system_launcher_containerized --groups language_processing
    environment:
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
    depends_on:
      - core_services
      - gpu_intensive
    networks:
      - backplane
    ports:
      - "5709:5709"   # NLUAgent
      - "5710:5710"   # AdvancedCommandHandler
      - "5595:5595"   # TranslationService
      - "5711:5711"   # ChitchatAgent
      - "5637:5637"   # Responder
      - "5701:5701"   # IntentionValidatorAgent
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "6"
          memory: 8G
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5709/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  # ============================================================================
  # CONTAINER GROUP 4: AUDIO SPEECH (9 agents)
  # Complete speech processing pipeline
  # ============================================================================
  audio_speech:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/audio_speech:latest
    container_name: mainpc-audio-speech
    command: python -m main_pc_code.system_launcher_containerized --groups speech_services,audio_interface
    environment:
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
    depends_on:
      - core_services
      - gpu_intensive
    networks:
      - backplane
    ports:
      - "5800:5800"   # STTService
      - "5801:5801"   # TTSService
      - "6553:6553"   # StreamingSpeechRecognition
      - "5562:5562"   # StreamingTTSAgent
      - "5579:5579"   # StreamingLanguageAnalyzer
      - "6552:6552"   # WakeWordDetector
      - "6550:6550"   # AudioCapture
      - "6551:6551"   # FusedAudioPreprocessor
      - "5576:5576"   # StreamingInterruptHandler
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 6G
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5800/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  # ============================================================================
  # CONTAINER GROUP 5: MEMORY SYSTEM (3 agents)
  # MemoryClient, SessionMemoryAgent, KnowledgeBase
  # ============================================================================
  memory_system:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/memory_system:latest
    container_name: mainpc-memory-system
    command: python -m main_pc_code.system_launcher_containerized --groups memory_system
    environment:
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
    depends_on:
      - core_services
    networks:
      - backplane
    ports:
      - "5713:5713"   # MemoryClient
      - "5574:5574"   # SessionMemoryAgent
      - "5715:5715"   # KnowledgeBase
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5713/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  # ============================================================================
  # CONTAINER GROUP 6: EMOTION SYSTEM (6 agents)
  # EmotionEngine, MoodTrackerAgent, HumanAwarenessAgent, ToneDetector, VoiceProfilingAgent, EmpathyAgent
  # ============================================================================
  emotion_system:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/emotion_system:latest
    container_name: mainpc-emotion-system
    command: python -m main_pc_code.system_launcher_containerized --groups emotion_system
    environment:
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
    depends_on:
      - core_services
    networks:
      - backplane
    ports:
      - "5590:5590"   # EmotionEngine
      - "5704:5704"   # MoodTrackerAgent
      - "5705:5705"   # HumanAwarenessAgent
      - "5625:5625"   # ToneDetector
      - "5708:5708"   # VoiceProfilingAgent
      - "5703:5703"   # EmpathyAgent
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "3"
          memory: 4G
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5590/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  # ============================================================================
  # CONTAINER GROUP 7: LEARNING SERVICES (7 agents)
  # Light GPU usage for learning and training
  # ============================================================================
  learning_services:
    build:
      context: .
      dockerfile: docker/mainpc/Dockerfile
    image: mainpc/learning_services:latest
    container_name: mainpc-learning-services
    command: python -m main_pc_code.system_launcher_containerized --groups learning_knowledge,utility_services
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - REDIS_URL=redis://redis:6380/0
      - LOG_LEVEL=INFO
      - MACHINE_TYPE=mainpc
      - PYTHONPATH=/app
    depends_on:
      - core_services
      - gpu_intensive
    networks:
      - backplane
    ports:
      - "7210:7210"   # LearningOrchestrationService
      - "7202:7202"   # LearningOpportunityDetector
      - "5580:5580"   # LearningManager
      - "5638:5638"   # ActiveLearningMonitor
      - "5643:5643"   # LearningAdjusterAgent
      - "5660:5660"   # SelfTrainingOrchestrator
      - "5642:5642"   # LocalFineTunerAgent
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: "4"
        reservations:
          devices:
            - capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:7210/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

networks:
  backplane:
    driver: bridge

volumes:
  redis_data: 