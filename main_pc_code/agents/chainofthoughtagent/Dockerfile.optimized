# syntax=docker/dockerfile:1.5
# ChainOfThoughtAgent - GPU/LLM service (MAINPC)
FROM ghcr.io/haymayndzultra/family-llm-cu121:20250812-latest AS base

ARG MACHINE=mainpc
ENV PYTHONUNBUFFERED=1
    TORCH_CUDA_ARCH_LIST="8.9" \
    GPU_VISIBLE_DEVICES=${{GPU_VISIBLE_DEVICES:-0}}

WORKDIR /app

# Copy machine profile
COPY config/machine-profiles/${MACHINE}.json /etc/machine-profile.json

# Builder stage
FROM base AS builder
COPY requirements/chainofthoughtagent.txt ./requirements.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --no-cache-dir --require-hashes -r requirements.txt

# Runtime stage  
FROM base AS runtime
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY chainofthoughtagent/ ./chainofthoughtagent
COPY entrypoints/chainofthoughtagent_entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

USER appuser

# Health check on port 6612
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -sf http://localhost:6612/health || exit 1

# Expose service and health ports
EXPOSE 5612 6612

ENTRYPOINT ["/usr/bin/tini","--"]
CMD ["/entrypoint.sh"]
