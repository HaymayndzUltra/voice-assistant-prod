import os
import sys
import json
import time
import zmq
import tempfile
import logging
import argparse
import sounddevice as sd
import numpy as np
from collections import OrderedDict

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("XTTS_Agent")

# Constants
TTS_PORT = 5562  # ZMQ port for TTS requests
SAMPLE_RATE = 24000  # Default sample rate for audio playback
MAX_CACHE_SIZE = 50  # Maximum number of cached audio samples

class XTTSAgent:
    """XTTS Agent for high-quality speech synthesis"""
    
    def __init__(self, test_mode=False):
        """Initialize the XTTS agent"""
        logger.info("Initializing XTTS Agent")
        
        # Set up ZMQ for communication
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.REP)
        self.socket.bind(f"tcp://*:{TTS_PORT}")
        
        # Initialize audio cache (OrderedDict maintains insertion order)
        self.cache = OrderedDict()
        
        # Set up voice samples directory
        self.voice_samples_dir = os.path.join(
            os.path.dirname(os.path.abspath(__file__)),
            "voice_samples"
        )
        
        # Create voice samples directory if it doesn't exist
        if not os.path.exists(self.voice_samples_dir):
            os.makedirs(self.voice_samples_dir)
            logger.info(f"Created voice samples directory at {self.voice_samples_dir}")
        
        # Set default voice options
        self.language = "en"
        self.speaker_wav = None  # Use default XTTS speaker
        self.temperature = 0.7   # Voice variability
        
        # Available voices seen in logs
        self.available_speakers = ["Ana Florence", "Claribel Dervla", "Daisy Studious", "Gracie Wise", "Tammie Ema", "Alison Dietlinde"]
        
        # Define Filipino voice options (for Filipino accent)
        self.filipino_voice_sample = os.path.join(self.voice_samples_dir, "filipino_sample.wav")
        
        # If Filipino sample doesn't exist, log a message with instructions
        if not os.path.exists(self.filipino_voice_sample):
            logger.info(f"Filipino voice sample not found at {self.filipino_voice_sample}")
            logger.info("To use Filipino accent, record a 10-15 second WAV file and save it as 'filipino_sample.wav' in the voice_samples directory")
        else:
            logger.info(f"Filipino voice sample found at {self.filipino_voice_sample}")
        
        # Initialize XTTS
        self._initialize_tts()
        
        # Test mode - speak a sample sentence
        if test_mode:
            self.speak("XTTS agent initialized and ready.")
    
    def _initialize_tts(self):
        """Initialize the XTTS model"""
        try:
            # Try to initialize XTTS from TTS module
            try:
                from TTS.api import TTS
                import torch
                
                # Check if CUDA is available
                device = "cuda" if torch.cuda.is_available() else "cpu"
                logger.info(f"Using device: {device}")
                
                # Initialize the XTTS model
                logger.info("Loading XTTS model...")
                self.tts_model = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
                logger.info("XTTS model loaded successfully")
                
                # Check available languages
                if hasattr(self.tts_model, 'languages'):
                    logger.info(f"Available languages: {self.tts_model.languages}")
            except Exception as e:
                logger.error(f"Error initializing XTTS: {e}")
                self.tts_model = None
                raise
                
        except Exception as e:
            logger.error(f"Failed to initialize XTTS: {e}")
            logger.info("Falling back to Windows SAPI for TTS")
            
            # Try to use Windows SAPI as fallback
            try:
                import win32com.client
                self.win_speaker = win32com.client.Dispatch("SAPI.SpVoice")
                self.win_speaker.Speak("XTTS failed to load. Using Windows SAPI as fallback.")
            except Exception as sapi_error:
                logger.error(f"Failed to initialize Windows SAPI: {sapi_error}")
    
    def speak(self, text, add_to_cache=True, speech_end_time=None):
        """Speak the provided text using XTTS"""
        if not text or text.strip() == "":
            logger.warning("Empty text provided to speak function")
            return False
        
        # Process text into sentences
        sentences = self._split_into_sentences(text)
        logger.info(f"Split text into {len(sentences)} sentences")
        
        # Create a cache key from text and voice settings
        cache_key = f"{text}_{self.language}_{self.speaker_wav}"
        
        # Check if we have this audio cached
        cached_audio = self.cache.get(cache_key)
        if cached_audio is not None:
            logger.info("Using cached audio")
            if speech_end_time is not None:
                playback_start = time.time()
                latency = playback_start - speech_end_time
                logger.info(f"[LATENCY] Total time from speech end to TTS playback: {latency:.2f}s")
            sd.play(cached_audio, SAMPLE_RATE)
            sd.wait()
            return True
        
        try:
            for i, sentence in enumerate(sentences):
                if not sentence.strip():
                    continue
                    
                logger.info(f"Speaking sentence {i+1}/{len(sentences)}: '{sentence[:30]}...'")
                
                # Check if we have a proper XTTS model
                if hasattr(self, "tts_model"):
                    # Generate speech using XTTS
                    logger.info(f"Using XTTS to speak: '{sentence[:30]}...'")
                    
                    # Set up speaker sample if available
                    speaker_wav = self.speaker_wav
                    if speaker_wav and not os.path.exists(speaker_wav):
                        logger.warning(f"Speaker wav file not found: {speaker_wav}")
                        speaker_wav = None
                    
                    # Generate speech with XTTS
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_f:
                        temp_path = temp_f.name
                    
                    # Get valid speakers for XTTS v2
                    # In XTTS v2, we need to use a valid speaker from the model's available speakers
                    # Instead of hardcoding, we'll try to find what speakers are actually available
                    try:
                        # First check if we already have a list of available speakers
                        if not hasattr(self, 'available_speakers') or not self.available_speakers:
                            # Try to get available speakers from the model
                            if hasattr(self.tts_model, 'synthesizer') and \
                               hasattr(self.tts_model.synthesizer, 'tts_model') and \
                               hasattr(self.tts_model.synthesizer.tts_model, 'speaker_manager') and \
                               hasattr(self.tts_model.synthesizer.tts_model.speaker_manager, 'speakers'):
                                self.available_speakers = list(self.tts_model.synthesizer.tts_model.speaker_manager.speakers.keys())
                                logger.info(f"Found available speakers: {self.available_speakers[:5]}{'...' if len(self.available_speakers) > 5 else ''}")
                            else:
                                self.available_speakers = []
                                
                        # If we have speakers, use an appropriate one for the language
                        if self.available_speakers:
                            # Try to find a speaker that matches the language
                            lang_speakers = [s for s in self.available_speakers if self.language in s]
                            if lang_speakers:
                                speaker_name = lang_speakers[0]
                            else:
                                speaker_name = self.available_speakers[0]
                        else:
                            # No speakers found - this will likely fail, but try a common one
                            speaker_name = "1" # XTTS v2 often uses numbered speakers
                    except Exception as e:
                        logger.warning(f"Error finding speakers, will use default: {e}")
                        speaker_name = "1"  # Fall back to a common speaker name
                    
                    logger.info(f"XTTS params: language={self.language}, speaker={speaker_name}, custom_voice={'Yes' if speaker_wav else 'No'}")
                    
                    # Voice settings
                    # Use the user's configured voice
                    if hasattr(self, 'use_filipino') and self.use_filipino:
                        logger.info("Using Filipino voice configuration")
                    
                    # Generate speech with XTTS
                    try:
                        # Generate base speech first
                        if speaker_wav:
                            self.tts_model.tts_to_file(
                                text=sentence,
                                file_path=temp_path,
                                speaker_wav=speaker_wav,
                                language=self.language,
                                temperature=self.temperature
                            )
                        else:
                            self.tts_model.tts_to_file(
                                text=sentence,
                                file_path=temp_path,
                                speaker_name=speaker_name,
                                language=self.language,
                                temperature=self.temperature
                            )
                        
                        # Voice processing already applied via the tetey.wav sample
                    except Exception as tts_error:
                        logger.error(f"XTTS error: {tts_error}")
                        import traceback
                        logger.error(traceback.format_exc())
                        
                        # Fall back to Windows SAPI if available
                        if hasattr(self, 'win_speaker'):
                            logger.info(f"Falling back to Windows SAPI for: '{sentence}'")
                            self.win_speaker.Speak(sentence)
                            continue
                        else:
                            logger.error("No fallback TTS available")
                            return False
                    
                    # Play the generated audio
                    try:
                        import soundfile as sf
                        audio, sample_rate = sf.read(temp_path)
                        
                        # Cache the audio if requested
                        if add_to_cache:
                            self._add_to_cache(cache_key, audio)
                        
                        if speech_end_time is not None:
                            playback_start = time.time()
                            latency = playback_start - speech_end_time
                            logger.info(f"[LATENCY] Total time from speech end to TTS playback: {latency:.2f}s")
                        sd.play(audio, sample_rate)
                        sd.wait()  # Wait for playback to finish
                        
                        # Clean up the temporary file
                        try:
                            os.unlink(temp_path)
                        except Exception as e:
                            logger.warning(f"Error removing temp file: {e}")
                        
                        logger.info(f"✓ Successfully played audio for sentence {i+1}")
                    except Exception as audio_error:
                        logger.error(f"Error playing audio: {audio_error}")
                        
                        # Try to play with Windows SAPI as fallback
                        if hasattr(self, 'win_speaker'):
                            logger.info(f"Falling back to Windows SAPI for: '{sentence}'")
                            self.win_speaker.Speak(sentence)
                        else:
                            return False
                
                # Fall back to Windows SAPI if XTTS isn't available
                elif hasattr(self, 'win_speaker'):
                    logger.info(f"Using Windows SAPI for: '{sentence}'")
                    self.win_speaker.Speak(sentence)
                
                else:
                    logger.error("No TTS system available")
                    return False
            
            return True
        
        except Exception as e:
            logger.error(f"Error in speak: {e}")
            return False
    
    def _split_into_sentences(self, text):
        """Split text into sentences for better TTS results"""
        # Simple sentence splitting based on punctuation
        sentences = []
        current = ""
        
        # Split on sentence-ending punctuation
        for char in text:
            current += char
            if char in '.!?':
                sentences.append(current.strip())
                current = ""
        
        # Add any remaining text as a final sentence
        if current.strip():
            sentences.append(current.strip())
        
        # If no sentences were created, return the original text
        if not sentences:
            sentences = [text]
        
        return sentences
    
    def _add_to_cache(self, key, audio):
        """Add audio to the cache with LRU behavior"""
        # If cache is full, remove the oldest item (first inserted)
        if len(self.cache) >= MAX_CACHE_SIZE:
            self.cache.popitem(last=False)
        
        # Add the new item
        self.cache[key] = audio
    
    def run(self):
        """Run the TTS agent, listening for ZMQ requests"""
        logger.info("Starting XTTS Agent")
        
        try:
            while True:
                # Wait for next request from client
                message = self.socket.recv_string()
                logger.info(f"Received request: {message[:100]}...")
                
                try:
                    # Parse the JSON message
                    data = json.loads(message)
                    command = data.get("command")
                    action = data.get("action")
                    
                    # Health check support
                    if (action == "health_check") or (command == "health_check"):
                        self.socket.send_string(json.dumps({"status": "healthy", "service": "XTTS_Agent"}))
                        continue
                    
                    if command == "speak":
                        text = data.get("text", "")
                        lang = data.get("language", self.language)
                        
                        # Update language if specified
                        if lang != self.language:
                            self.language = lang
                            logger.info(f"Language set to {self.language}")
                        
                        logger.info(f"Received speak command: '{text[:50]}...'")
                        
                        # Get speech_end_time from message if present
                        speech_end_time = data.get("speech_end_time")
                        if speech_end_time is not None:
                            try:
                                speech_end_time = float(speech_end_time)
                            except Exception:
                                speech_end_time = None
                        # Speak the text
                        success = self.speak(text, speech_end_time=speech_end_time)
                        
                        # Send response
                        if success:
                            self.socket.send_string(json.dumps({"status": "ok", "message": "Speech completed"}))
                        else:
                            self.socket.send_string(json.dumps({"status": "error", "message": "Failed to speak"}))
                    
                    elif command == "set_voice":
                        # Update voice settings
                        self.language = data.get("language", self.language)
                        speaker_wav = data.get("speaker_wav")
                        if speaker_wav and os.path.exists(speaker_wav):
                            self.speaker_wav = speaker_wav
                        
                        # Check for Filipino accent mode
                        filipino_accent = data.get("filipino_accent", False)
                        if filipino_accent:
                            if os.path.exists(self.filipino_voice_sample):
                                self.speaker_wav = self.filipino_voice_sample
                                logger.info(f"Filipino accent mode activated using {self.filipino_voice_sample}")
                            else:
                                logger.warning("Filipino voice sample not found, cannot activate Filipino accent")
                        
                        # Send response
                        self.socket.send_string(json.dumps({"status": "ok", "message": "Voice settings updated"}))
                    
                    else:
                        logger.warning(f"Unknown command: {command}")
                        self.socket.send_string(json.dumps({"status": "error", "message": "Unknown command"}))
                
                except Exception as e:
                    logger.error(f"Error processing request: {e}")
                    self.socket.send_string(json.dumps({"status": "error", "message": str(e)}))
        
        except KeyboardInterrupt:
            logger.info("Keyboard interrupt received, shutting down")
        except Exception as e:
            logger.error(f"Error in run loop: {e}")
        finally:
            # Clean up
            self.socket.close()
            self.context.term()

if __name__ == "__main__":
    import argparse
    
    # Set up argument parser
    parser = argparse.ArgumentParser(description='XTTS Text-to-Speech Agent')
    parser.add_argument('--test', action='store_true', help='Run in test mode with a sample sentence')
    parser.add_argument('--use_filipino', action='store_true', help='Use Filipino voice sample')
    args = parser.parse_args()
    
    # Check environment variable for Filipino voice
    use_filipino = args.use_filipino or os.environ.get('XTTS_USE_FILIPINO', '0') == '1'
    
    # Create and run agent
    agent = XTTSAgent(test_mode=bool(args.test))
    
    # Use Filipino voice sample if specified
    if use_filipino:
        agent.speaker_wav = "C:/Users/haymayndz/Desktop/Voice assistant/tetey1.wav"
        agent.use_filipino = True  # Optional: used for masculinization logic
        print(f"Using Tetey voice sample: {agent.speaker_wav}")
    
    # If test mode
    if args.test:
        print(f"Test mode: Speaking '{args.test}'")
        agent.speak(args.test)
        sys.exit(0)
    
    # Normal server mode
    print(f"Listening on ZMQ port {TTS_PORT}")
    print("Using XTTS for high-quality TTS")
    agent.run()
