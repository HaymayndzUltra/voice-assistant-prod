# Group: GPU Infrastructure

Ito ang mga agents na kabilang sa grupong ito:

---

### ğŸ§  AGENT PROFILE: GGUFModelManager
- **Main Class:** `GGUFModelManager`
- **Host Machine:** Main PC
- **Role:** Central manager for local GGUF Llama-cpp models (load/unload, metadata, inference helper).
- **ğŸ¯ Responsibilities:**
  â€¢ Mag-maintain ng catalogue ng GGUF models (metadata, VRAM estimates).
  â€¢ Mag-load at mag-unload ng models on demand via `load_model` / `unload_model`.
  â€¢ Mag-provide text generation interface thru `generate_text()`.
  â€¢ Mag-track idle models at auto-unload (default 300 s).
  â€¢ Mag-publish health & model-status info.
- **ğŸ”— Interactions:**
  â€¢ Used by `CodeGeneratorAgent` & `ModelManagerAgent` for generation.
  â€¢ Error-Bus PUB (`tcp://192.168.100.17:7150`).
- **ğŸ§¬ Technical Deep Dive:**
  â€¢ ZMQ REP `tcp://0.0.0.0:5575`; health REP `5576` (BaseAgent default).
  â€¢ Uses llama-cpp-python (optional; warns if missing).
  â€¢ Keeps `loaded_models` dict and `GGUFStateTracker` (port 5576) for VRAM accounting.
  â€¢ Model metadata read from `config/system_config.py` (serving_method = gguf_direct).
- **âš ï¸ Panganib:**
  â€¢ High VRAM usage â€” may fail load if insufficient.
  â€¢ Llama-cpp not available â‡’ inability to serve GGUF models.
  â€¢ Thread safety issues when parallel load/unload (lock mitigated).
- **ğŸ“¡ Communication Details:**
  - **ğŸ”Œ Health Port:** 5576
  - **ğŸ›°ï¸ Port:** 5575
  - **ğŸ”§ Environment Variables:** `PC2_IP`, `SECURE_ZMQ`, `LLAMA_CPP_THREADS`, `MODEL_IDLE_TIMEOUT_SECONDS`
  - **ğŸ“‘ Sample Request:**
    ```json
    { "action": "load_model", "model_id": "codellama" }
    ```
  - **ğŸ“Š Resource Footprint (baseline):** ~120 MB RAM + VRAM per model; CPU ~3 % idle.
  - **ğŸ”’ Security & Tuning Flags:** secure-ZMQ toggle; idle-unload timeout; VRAM budget via VRAMOptimizer.

---
### ğŸ§  AGENT PROFILE: ModelManagerAgent
- **Main Class:** `ModelManagerAgent`
- **Host Machine:** Main PC
- **Role:** High-level orchestrator for loading, unloading, routing, and monitoring of every model type (LLMs, STT, TTS, Ollama, custom API, GGUF, etc.).
- **ğŸ¯ Responsibilities:**
  â€¢ Mag-route generation requests to appropriate model.
  â€¢ Mag-handle STT (speech-to-text) and TTS (text-to-speech) requests.
  â€¢ Mag-manage VRAM via coordination with `VRAMOptimizerAgent`.
  â€¢ Auto-unload idle models; maintain cache files.
  â€¢ Mag-expose rich JSON API (`load_model`, `unload_model`, `generate`, `status`).
- **ğŸ”— Interactions:**
  â€¢ `VRAMOptimizerAgent` (consultation & unload requests).
  â€¢ `SystemDigitalTwin` (status updates).
  â€¢ `GGUFModelManager` for GGUF models.
  â€¢ `STTService` and `TTSService` for audio processing.
  â€¢ Error-Bus PUB.
- **ğŸ§¬ Technical Deep Dive:**
  â€¢ ZMQ REP `tcp://0.0.0.0:5570`; health REP `5571`.
  â€¢ Handles GPU/CPU detection, VRAM budget (default 80 % of GPU).
  â€¢ Log rotation (5 MB x5) at `logs/mma_*.log`.
  â€¢ Background threads: VRAM management, health check, model idle checker.
  â€¢ Uses `llm_config.yaml` for model routing policies including STT and TTS models.
- **âš ï¸ Panganib:**
  â€¢ Complex concurrency â‡’ race conditions on `models` dict.
  â€¢ VRAM mis-estimation âœ OOM.
  â€¢ Large log files if debug enabled.
- **ğŸ“¡ Communication Details:**
  - **ğŸ”Œ Health Port:** 5571
  - **ğŸ›°ï¸ Port:** 5570
  - **ğŸ”§ Environment Variables:** `MODEL_MANAGER_PORT`, `PC2_IP`, `SECURE_ZMQ`, `LLM_CONFIG_PATH`, `vram_budget_percentage`
  - **ğŸ“‘ Sample Request:**
    ```json
    { "action": "generate", "model_pref": "quality", "prompt": "Hello, world!" }
    ```
  - **ğŸ“Š Resource Footprint (baseline):** ~220 MB RAM idle; GPU VRAM varies; CPU <6 % idle.
  - **ğŸ”’ Security & Tuning Flags:** secure-ZMQ; VRAM budget %; idle unload timeout.

---
### ğŸ§  AGENT PROFILE: VRAMOptimizerAgent
- **Main Class:** `VramOptimizerAgent`
- **Host Machine:** Main PC
- **Role:** Monitors GPU VRAM usage across devices and coordinates model unload/load to stay within budget.
- **ğŸ¯ Responsibilities:**
  â€¢ Poll `SystemDigitalTwin` & local metrics for VRAM usage.
  â€¢ Advise `ModelManagerAgent` whether a new model can be loaded (`can_load_model`).
  â€¢ Trigger unload of least-used models when thresholds exceeded.
  â€¢ Predictive optimisation (defragmentation, idle tracking).
- **ğŸ”— Interactions:**
  â€¢ `ModelManagerAgent` (REQ/REP).
  â€¢ `SystemDigitalTwin` (REQ/REP) for global metrics.
  â€¢ Error-Bus PUB.
- **ğŸ§¬ Technical Deep Dive:**
  â€¢ Default ZMQ REP `tcp://0.0.0.0:5000`; health REP `5001`.
  â€¢ Uses thresholds: critical 0.9, warning 0.75, safe 0.5 (configurable).
  â€¢ Background threads: `_monitor_vram`, `_optimize_memory`, `_predict_usage`, `_monitor_idle_models`.
- **âš ï¸ Panganib:**
  â€¢ Incorrect prediction may unload active models âœ latency.
  â€¢ Thresholds too low â‡’ constant churn.
  â€¢ Dependency on SystemDigitalTwin availability.
- **ğŸ“¡ Communication Details:**
  - **ğŸ”Œ Health Port:** 5001
  - **ğŸ›°ï¸ Port:** 5000
  - **ğŸ”§ Environment Variables:** `PC2_IP`, `SECURE_ZMQ`, `vram_optimizer.*` thresholds
  - **ğŸ“‘ Sample Request:**
    ```json
    { "action": "can_load_model", "model_vram_mb": 8000 }
    ```
  - **ğŸ“Š Resource Footprint (baseline):** ~140 MB RAM; CPU 4-7 % due to monitoring threads.
  - **ğŸ”’ Security & Tuning Flags:** secure-ZMQ; `defragmentation_threshold`; idle timeout.

---
### ğŸ§  AGENT PROFILE: PredictiveLoader
- **Main Class:** `PredictiveLoader`
- **Host Machine:** Main PC
- **Role:** Forecasts near-future model usage based on historical patterns and preloads models to reduce latency.
- **ğŸ¯ Responsibilities:**
  â€¢ Collect model usage data (via `record_usage`).
  â€¢ Predict upcoming models (`predict_models`) within look-ahead window (default 5 min).
  â€¢ Instruct `ModelManagerAgent` to preload required models.
  â€¢ Provide health endpoint.
- **ğŸ”— Interactions:**
  â€¢ `RequestCoordinator` for usage signals.
  â€¢ `ModelManagerAgent` for preload commands.
  â€¢ Error-Bus PUB.
- **ğŸ§¬ Technical Deep Dive:**
  â€¢ ZMQ REP `tcp://0.0.0.0:5617`; health REP `5618`.
  â€¢ Maintains `model_usage` dict; prediction loop runs every 60 s.
  â€¢ Config keys: `prediction_window` (1 h), `lookahead_window` (5 min).
- **âš ï¸ Panganib:**
  â€¢ Wrong predictions waste VRAM.
  â€¢ Connection loss with RequestCoordinator.
- **ğŸ“¡ Communication Details:**
  - **ğŸ”Œ Health Port:** 5618
  - **ğŸ›°ï¸ Port:** 5617
  - **ğŸ”§ Environment Variables:** `prediction_window`, `lookahead_window`, `PC2_IP`, `SECURE_ZMQ`
  - **ğŸ“‘ Sample Request:**
    ```json
    { "action": "record_usage", "model_id": "gemma-7b" }
    ```
  - **ğŸ“Š Resource Footprint (baseline):** ~90 MB RAM; CPU 3 %.
  - **ğŸ”’ Security & Tuning Flags:** secure-ZMQ; idle monitor intervals.

---
### Pattern Compliance Checklist
| Agent | Tugma sa Pattern? | Reason (kung X) |
|-------|-------------------|-----------------|
| GGUFModelManager | âœ“ | |
| ModelManagerAgent | âœ“ | |
| VRAMOptimizerAgent | âœ“ | |
| PredictiveLoader | âœ“ | |

---

### Container Grouping Updates
- This group has been renamed from **ai_models_gpu_services** to **gpu_infrastructure** to better reflect its focus on core GPU resource management.
- The reasoning agents (ChainOfThoughtAgent, GoTToTAgent, CognitiveModelAgent) have been moved to a dedicated **reasoning_services** group.
- This reorganization provides clearer separation between infrastructure services and higher-level reasoning capabilities.
