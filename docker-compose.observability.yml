version: "3.9"

# Observability Stack for AI System
# Jaeger, OpenTelemetry Collector, Enhanced Grafana with SLO Dashboards

services:
  # Jaeger - Distributed Tracing Backend
  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: jaeger-ai-system
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=http://prometheus:9090
      - PROMETHEUS_QUERY_SUPPORT_SPANMETRICS_CONNECTOR=true
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
      - "9411:9411"    # Zipkin
    networks:
      - ai-observability
    volumes:
      - jaeger-data:/tmp
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.92.0
    container_name: otel-collector-ai
    command: ["--config=/etc/otelcol-contrib/otel-collector.yaml"]
    volumes:
      - ./config/observability/otel-collector.yaml:/etc/otelcol-contrib/otel-collector.yaml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # Health check extension
    depends_on:
      - jaeger
      - prometheus
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
    environment:
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
      - PROMETHEUS_ENDPOINT=http://prometheus:9090/api/v1/write

  # Enhanced Prometheus with longer retention
  prometheus:
    image: prom/prometheus:v2.48.1
    container_name: prometheus-ai-enhanced
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'  # 30 days retention
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "9090:9090"
    volumes:
      - ./config/observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/observability/alert-rules:/etc/prometheus/rules:ro
      - prometheus-data:/prometheus
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G

  # Enhanced Grafana with SLO Dashboards
  grafana-enhanced:
    image: grafana/grafana:10.2.3
    container_name: grafana-ai-enhanced
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=ai-system-2024
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel,yesoreyeram-boomtable-panel,vonage-status-panel
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_CONTENT_TYPE_PROTECTION=true
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY=true
    ports:
      - "3000:3000"
    volumes:
      - grafana-enhanced-data:/var/lib/grafana
      - ./config/observability/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./config/observability/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ./config/observability/grafana/alerting:/etc/grafana/provisioning/alerting:ro
    depends_on:
      - prometheus
      - jaeger
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Alertmanager for SLO violations
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager-ai
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
      - '--cluster.advertise-address=0.0.0.0:9093'
    ports:
      - "9093:9093"
    volumes:
      - ./config/observability/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

  # Redis for trace storage and caching
  redis-traces:
    image: redis:7.2-alpine
    container_name: redis-traces-ai
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    ports:
      - "6380:6379"
    volumes:
      - redis-traces-data:/data
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 2.5G
          cpus: '0.5'
        reservations:
          memory: 2G

  # Tempo for additional trace storage (optional)
  tempo:
    image: grafana/tempo:2.3.1
    container_name: tempo-ai
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./config/observability/tempo.yaml:/etc/tempo.yaml:ro
      - tempo-data:/tmp/tempo
    ports:
      - "3200:3200"   # Tempo HTTP
      - "4317:4317"   # OTLP gRPC (alternative)
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Vector for log aggregation and processing
  vector:
    image: timberio/vector:0.34.2-alpine
    container_name: vector-ai-logs
    command: ["--config", "/etc/vector/vector.yaml"]
    volumes:
      - ./config/observability/vector.yaml:/etc/vector/vector.yaml:ro
      - /var/log:/host/var/log:ro
      - /var/lib/docker/containers:/host/var/lib/docker/containers:ro
    ports:
      - "8686:8686"   # Vector API
    networks:
      - ai-observability
    depends_on:
      - otel-collector
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Loki for log storage
  loki:
    image: grafana/loki:2.9.3
    container_name: loki-ai
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ./config/observability/loki.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    networks:
      - ai-observability
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # SLO Exporter for custom SLO metrics
  slo-exporter:
    image: prometheus/prometheus:v2.48.1  # Using Prometheus image with custom script
    container_name: slo-exporter-ai
    command: ["/bin/sh", "-c", "while true; do python3 /scripts/slo_calculator.py; sleep 60; done"]
    volumes:
      - ./scripts/slo_calculator.py:/scripts/slo_calculator.py:ro
      - ./config/observability/slo-config.yaml:/config/slo-config.yaml:ro
    networks:
      - ai-observability
    depends_on:
      - prometheus
    environment:
      - PROMETHEUS_URL=http://prometheus:9090
      - SLO_CONFIG_PATH=/config/slo-config.yaml
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.1'

networks:
  ai-observability:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  jaeger-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-enhanced-data:
    driver: local
  alertmanager-data:
    driver: local
  redis-traces-data:
    driver: local
  tempo-data:
    driver: local
  loki-data:
    driver: local

# Health check for the entire observability stack
x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s