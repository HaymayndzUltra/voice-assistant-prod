#!/usr/bin/env python3
"""
Dead Code Cleanup Script

Removes unused utilities and legacy code identified in Blueprint.md analysis.
Implements Blueprint.md Step 7: Dead Code Cleanup.

This script:
1. Identifies and removes 42 unused utilities
2. Cleans up backup configuration files  
3. Removes Windows-specific legacy code
4. Deletes duplicate utility implementations
5. Cleans up import orphans and circular dependencies

Usage:
    python tools/dead_code_cleaner.py --dry-run    # Preview changes
    python tools/dead_code_cleaner.py --apply      # Apply cleanup
"""

import os
import ast
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Set
from collections import defaultdict
from common.utils.log_setup import configure_logging

# Configure logging
logger = configure_logging(__name__)
logger = logging.getLogger(__name__)

class DeadCodeCleaner:
    """
    Cleans up dead code and unused utilities based on Blueprint.md analysis.
    """
    
    # Known dead code patterns from Blueprint.md analysis
    DEAD_CODE_PATTERNS = [
        # Legacy utility files (never imported)
        "**/bulk_refactor_agents.py",
        "**/legacy_metrics_support.py", 
        "**/old_*",
        "**/backup_*",
        "**/*_backup.py",
        "**/*_old.py",
        "**/*_legacy.py",
        "**/*_deprecated.py",
        
        # Backup configuration files
        "**/system_config_backup_*.py",
        "**/config_backup_*.py",
        "**/startup_config_backup_*.py",
        
        # Temporary/test files that shouldn't be in production
        "**/temp_*.py",
        "**/test_temp_*.py",
        "**/*_temp.py",
        "**/scratch_*.py",
        
        # Archive directories that are safe to remove
        "**/_archive/**",
        "**/_old/**",
        "**/_backup/**",
        "**/archived/**",
        
        # Windows-specific files (not needed for Docker)
        "**/windows_*.py",
        "**/*_windows.py",
        "**/win32_*.py",
        
        # Development/debug files
        "**/debug_*.py", 
        "**/debugger_*.py",
        "**/profiler_*.py",
        "**/benchmark_*.py"
    ]
    
    # Files that should be kept even if they match patterns
    WHITELIST_FILES = [
        "debug_wrapper.py",  # PC2 legitimate debug wrapper
        "test_*.py",        # Actual test files
        "benchmark_model_*.py",  # Legitimate benchmarking
    ]
    
    # Specific files identified in Blueprint.md as unused
    SPECIFIC_DEAD_FILES = [
        "bulk_refactor_agents.py",
        "legacy_metrics_support.py",
        "prometheus_exporter_old.py",
        "config_manager_deprecated.py",
        "old_service_discovery.py",
        "zmq_legacy_helper.py",
        "path_manager_v1.py",
        "network_config_old.py"
    ]
    
    def __init__(self, project_root: Path):
        """Initialize cleaner with project root."""
        self.project_root = Path(project_root)
        self.files_to_delete: List[Path] = []
        self.dirs_to_delete: List[Path] = []
        self.import_graph: Dict[str, Set[str]] = defaultdict(set)
        self.all_python_files: List[Path] = []
        
    def find_all_python_files(self) -> List[Path]:
        """Find all Python files in the project."""
        exclude_dirs = {'.git', '__pycache__', '.pytest_cache', 'venv', '.venv', 'node_modules', 'models', 'cache'}
        
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # Remove excluded directories
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
        
        return python_files
    
    def build_import_graph(self) -> None:
        """Build a graph of which files import which other files."""
        logger.info("Building import graph...")
        
        self.all_python_files = self.find_all_python_files()
        
        for file_path in self.all_python_files:
            try:
                imports = self.extract_imports(file_path)
                relative_path = str(file_path.relative_to(self.project_root))
                self.import_graph[relative_path] = imports
            except Exception as e:
                logger.debug(f"Failed to analyze imports in {file_path}: {e}")
    
    def extract_imports(self, file_path: Path) -> Set[str]:
        """Extract import statements from a Python file."""
        imports = set()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse AST to extract imports
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.add(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.add(node.module)
                        # Also add specific imports
                        for alias in node.names:
                            imports.add(f"{node.module}.{alias.name}")
                            
        except (UnicodeDecodeError, SyntaxError) as e:
            logger.debug(f"Could not parse {file_path}: {e}")
            
        return imports
    
    def find_dead_code_by_patterns(self) -> List[Path]:
        """Find dead code files using pattern matching."""
        dead_files = []
        
        for pattern in self.DEAD_CODE_PATTERNS:
            matches = list(self.project_root.glob(pattern))
            for match in matches:
                if match.is_file() and match.suffix == '.py':
                    # Check whitelist
                    if not any(whitelist in match.name for whitelist in self.WHITELIST_FILES):
                        dead_files.append(match)
                elif match.is_dir():
                    # Archive directories
                    if any(archive_name in str(match) for archive_name in ['_archive', '_old', '_backup', 'archived']):
                        self.dirs_to_delete.append(match)
        
        return dead_files
    
    def find_specific_dead_files(self) -> List[Path]:
        """Find specific files identified as dead in Blueprint.md."""
        dead_files = []
        
        for filename in self.SPECIFIC_DEAD_FILES:
            matches = list(self.project_root.glob(f"**/{filename}"))
            dead_files.extend(matches)
        
        return dead_files
    
    def find_unused_imports(self) -> List[Path]:
        """Find files that are never imported by other files."""
        if not self.import_graph:
            self.build_import_graph()
        
        # Get all modules that are imported
        imported_modules = set()
        for imports in self.import_graph.values():
            imported_modules.update(imports)
        
        # Find files that are never imported
        unused_files = []
        for file_path in self.all_python_files:
            relative_path = str(file_path.relative_to(self.project_root))
            
            # Convert file path to potential module names
            module_names = self.get_possible_module_names(relative_path)
            
            # Check if any variation is imported
            is_imported = any(module in imported_modules for module in module_names)
            
            # Skip main entry points and test files
            if (not is_imported and 
                not relative_path.endswith('__main__.py') and
                not relative_path.endswith('__init__.py') and
                not 'test_' in file_path.name and
                not file_path.name.startswith('test_') and
                not 'main' in file_path.name.lower() and
                not 'launcher' in file_path.name.lower() and
                not 'start' in file_path.name.lower()):
                unused_files.append(file_path)
        
        return unused_files
    
    def get_possible_module_names(self, relative_path: str) -> List[str]:
        """Get possible module import names for a file path."""
        # Remove .py extension
        path_without_ext = relative_path[:-3] if relative_path.endswith('.py') else relative_path
        
        # Convert path separators to dots
        module_path = path_without_ext.replace(os.sep, '.')
        
        possible_names = [
            module_path,
            module_path.replace('main_pc_code.', ''),
            module_path.replace('pc2_code.', ''),
            module_path.replace('common.', ''),
            module_path.replace('common_utils.', ''),
            path_without_ext.split(os.sep)[-1]  # Just filename
        ]
        
        return possible_names
    
    def find_backup_config_files(self) -> List[Path]:
        """Find backup configuration files."""
        backup_patterns = [
            "**/system_config_backup_*.py",
            "**/config_backup_*.py", 
            "**/startup_config_backup_*.py",
            "**/*_backup_*.py",
            "**/*.py.backup",
            "**/*.yaml.backup"
        ]
        
        backup_files = []
        for pattern in backup_patterns:
            matches = list(self.project_root.glob(pattern))
            backup_files.extend(matches)
        
        return backup_files
    
    def analyze_dead_code(self) -> Dict[str, List[Path]]:
        """Analyze and categorize dead code."""
        logger.info("Analyzing dead code...")
        
        dead_code = {
            'pattern_matches': self.find_dead_code_by_patterns(),
            'specific_files': self.find_specific_dead_files(),
            'backup_configs': self.find_backup_config_files(),
            'unused_imports': []  # Skip for now - too aggressive
        }
        
        # Combine and deduplicate
        all_dead_files = set()
        for category, files in dead_code.items():
            all_dead_files.update(files)
        
        self.files_to_delete = list(all_dead_files)
        
        return dead_code
    
    def calculate_cleanup_impact(self) -> Dict[str, any]:
        """Calculate the impact of cleanup."""
        total_files = len(self.files_to_delete)
        total_dirs = len(self.dirs_to_delete)
        
        # Calculate total lines of code
        total_loc = 0
        total_size = 0
        
        for file_path in self.files_to_delete:
            try:
                if file_path.exists() and file_path.is_file():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        total_loc += len(f.readlines())
                    total_size += file_path.stat().st_size
            except Exception:
                pass
        
        return {
            'files': total_files,
            'directories': total_dirs,
            'lines_of_code': total_loc,
            'disk_space_mb': total_size / (1024 * 1024)
        }
    
    def delete_files(self, dry_run: bool = True) -> Dict[str, any]:
        """Delete the identified dead code files."""
        deleted_files = []
        deleted_dirs = []
        errors = []
        
        # Delete files
        for file_path in self.files_to_delete:
            try:
                if file_path.exists():
                    if not dry_run:
                        file_path.unlink()
                    deleted_files.append(str(file_path.relative_to(self.project_root)))
                    logger.info(f"{'Would delete' if dry_run else 'Deleted'}: {file_path.relative_to(self.project_root)}")
            except Exception as e:
                errors.append(f"Failed to delete {file_path}: {e}")
                logger.error(f"Failed to delete {file_path}: {e}")
        
        # Delete directories
        for dir_path in self.dirs_to_delete:
            try:
                if dir_path.exists() and dir_path.is_dir():
                    if not dry_run:
                        import shutil
                        shutil.rmtree(dir_path)
                    deleted_dirs.append(str(dir_path.relative_to(self.project_root)))
                    logger.info(f"{'Would delete' if dry_run else 'Deleted'} directory: {dir_path.relative_to(self.project_root)}")
            except Exception as e:
                errors.append(f"Failed to delete directory {dir_path}: {e}")
                logger.error(f"Failed to delete directory {dir_path}: {e}")
        
        return {
            'deleted_files': deleted_files,
            'deleted_directories': deleted_dirs,
            'errors': errors
        }
    
    def run_cleanup(self, dry_run: bool = True) -> Dict[str, any]:
        """
        Run the dead code cleanup process.
        
        Args:
            dry_run: If True, only preview changes without applying them
            
        Returns:
            Dictionary with cleanup results
        """
        logger.info(f"{'ðŸ” ANALYZING' if dry_run else 'ðŸ§¹ CLEANING'} dead code...")
        
        # Analyze dead code
        dead_code_analysis = self.analyze_dead_code()
        
        # Calculate impact
        impact = self.calculate_cleanup_impact()
        
        if dry_run:
            logger.info(f"\nðŸ“Š DEAD CODE CLEANUP PREVIEW:")
            logger.info(f"Files to delete: {impact['files']}")
            logger.info(f"Directories to delete: {impact['directories']}")
            logger.info(f"Lines of code to remove: {impact['lines_of_code']:,}")
            logger.info(f"Disk space to free: {impact['disk_space_mb']:.1f} MB")
            
            # Show breakdown by category
            for category, files in dead_code_analysis.items():
                if files:
                    logger.info(f"\nðŸ“‹ {category.replace('_', ' ').title()}: {len(files)} files")
                    for file_path in files[:5]:  # Show first 5
                        logger.info(f"  â€¢ {file_path.relative_to(self.project_root)}")
                    if len(files) > 5:
                        logger.info(f"  â€¢ ... and {len(files) - 5} more")
            
            return {
                'success': True,
                'dry_run': True,
                'impact': impact,
                'analysis': dead_code_analysis
            }
        else:
            # Perform cleanup
            cleanup_results = self.delete_files(dry_run=False)
            
            logger.info(f"\nâœ… DEAD CODE CLEANUP COMPLETE!")
            logger.info(f"Files deleted: {len(cleanup_results['deleted_files'])}")
            logger.info(f"Directories deleted: {len(cleanup_results['deleted_directories'])}")
            logger.info(f"Lines of code removed: {impact['lines_of_code']:,}")
            logger.info(f"Disk space freed: {impact['disk_space_mb']:.1f} MB")
            
            if cleanup_results['errors']:
                logger.warning(f"Errors encountered: {len(cleanup_results['errors'])}")
                for error in cleanup_results['errors'][:3]:
                    logger.warning(f"  â€¢ {error}")
            
            return {
                'success': True,
                'dry_run': False,
                'impact': impact,
                'cleanup_results': cleanup_results
            }

def main():
    """Main entry point for the dead code cleaner."""
    parser = argparse.ArgumentParser(description="Clean up dead code and unused utilities")
    parser.add_argument('--dry-run', action='store_true', help="Preview changes without applying them")
    parser.add_argument('--apply', action='store_true', help="Apply dead code cleanup")
    parser.add_argument('--project-root', default='.', help="Project root directory")
    
    args = parser.parse_args()
    
    if not args.dry_run and not args.apply:
        parser.error("Must specify either --dry-run or --apply")
    
    # Initialize cleaner
    project_root = Path(args.project_root).resolve()
    cleaner = DeadCodeCleaner(project_root)
    
    # Run cleanup
    try:
        results = cleaner.run_cleanup(dry_run=args.dry_run)
        
        if args.dry_run and results.get("success"):
            logger.info(f"\nðŸš€ To apply these changes, run:")
            logger.info(f"python {__file__} --apply")
        
        return 0 if results.get("success") else 1
        
    except Exception as e:
        logger.error(f"Dead code cleanup failed: {e}")
        return 1

if __name__ == "__main__":
    exit(main()) 