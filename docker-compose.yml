networks:
  ai_system_network:
    driver: bridge

services:
  # Redis for HA service registry
  redis:
    image: redis:7-alpine
    container_name: redis
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks: [ai_system_network]

  # Core Services
  core_services:
    build: .
    container_name: mainpc-core_services
    command: ["./scripts/run_group.sh", "core_services"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - redis
    networks: [ai_system_network]
    # Only expose the RequestCoordinator port as the main entry point
    ports:
      - "26002:26002"
      - "7100:7100"  # ServiceRegistry
      - "7120:7120"  # SystemDigitalTwin
      - "7125:7125"  # UnifiedSystemAgent
    healthcheck:
      test: ["CMD", "curl", "-f", "http://${LOCALHOST:-localhost}:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 300s
    restart: unless-stopped

  # Memory System
  memory_system:
    build: .
    container_name: mainpc-memory_system
    command: ["./scripts/run_group.sh", "memory_system"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - core_services
    networks: [ai_system_network]

    restart: unless-stopped

  # Utility Services
  utility_services:
    build: .
    container_name: mainpc-utility_services
    command: ["./scripts/run_group.sh", "utility_services"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - core_services
      - gpu_infrastructure
    networks: [ai_system_network]

    restart: unless-stopped

  # GPU Infrastructure
  gpu_infrastructure:
    build: .
    container_name: mainpc-gpu_infrastructure
    command: ["./scripts/run_group.sh", "gpu_infrastructure"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - core_services
    networks: [ai_system_network]

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # Reasoning Services
  reasoning_services:
    build: .
    container_name: mainpc-reasoning_services
    command: ["./scripts/run_group.sh", "reasoning_services"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - gpu_infrastructure
    networks: [ai_system_network]

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # Vision Processing
  vision_processing:
    build: .
    container_name: mainpc-vision_processing
    command: ["./scripts/run_group.sh", "vision_processing"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - gpu_infrastructure
    networks: [ai_system_network]

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # Learning Knowledge
  learning_knowledge:
    build: .
    container_name: mainpc-learning_knowledge
    command: ["./scripts/run_group.sh", "learning_knowledge"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - memory_system
      - utility_services
    networks: [ai_system_network]

    restart: unless-stopped

  # Language Processing
  language_processing:
    build: .
    container_name: mainpc-language_processing
    command: ["./scripts/run_group.sh", "language_processing"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - memory_system
      - utility_services
      - gpu_infrastructure
    networks: [ai_system_network]

    restart: unless-stopped

  # Speech Services
  speech_services:
    build: .
    container_name: mainpc-speech_services
    command: ["./scripts/run_group.sh", "speech_services"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - language_processing
      - gpu_infrastructure
    networks: [ai_system_network]

    restart: unless-stopped

  # Audio Interface
  audio_interface:
    build: .
    container_name: mainpc-audio_interface
    command: ["./scripts/run_group.sh", "audio_interface"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - speech_services
    networks: [ai_system_network]

    restart: unless-stopped

  # Emotion System
  emotion_system:
    build: .
    container_name: mainpc-emotion_system
    command: ["./scripts/run_group.sh", "emotion_system"]
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TEST_MODE=true
    depends_on:
      - core_services
    networks: [ai_system_network]

    restart: unless-stopped

volumes:
  redis_data:
    driver: local
